<?xml version="1.0" encoding="utf-8"?>

<section xml:id="topic-3-2-impacts">
  <title>Impact of Program Design</title>

  <introduction>
    <p>
      We are living in an age of rapid development in technology and automation.
      Software and hardware developers increasingly have real impacts on
      people’s lives. In computer science, we follow the following <url
      href="https://ethics.acm.org/">ACM professional code of ethics</url> which
      includes guidelines such as “Avoid harm” and “Respect privacy”.
    </p>

    <p>
      However, sometimes programs have unintended consequences. It can be
      difficult to ensure <term>system reliability</term>, which refers to a
      program being able to perform its tasks as expected under stated
      conditions without failure. Programmers should make an effort to maximize
      system reliability by testing the program with a variety of conditions.
    </p>

    <p>
      The creation of programs has impacts on society, the economy, and culture.
      These impacts can be both beneficial and harmful. Programs meant to fill a
      need or solve a problem can have unintended harmful effects beyond their
      intended use.
    </p>

    <p>
      Legal issues and intellectual property concerns can also arise when
      creating programs. Programmers often reuse code written by others and
      published as <term>open source</term> which is free to use. Incorporation
      of code that is not published as open source requires the programmer to
      obtain permission and often purchase the code before integrating it into
      their program. There are also newly arising issues with the use of AIs in
      coding.
    </p>

    <p>
      The fields of <term>AI (Artificial Intelligence)</term> and <term>Machine
      Learning</term> increasingly pose ethical questions in our world. For
      example, self-driving cars that use machine learning to learn to follow
      lanes and avoid collisions could make our world much safer. Self-driving
      cars do not get distracted by text messages and don’t drink and drive.
      However, what if the car needs to make an ethical decision about avoiding
      a collision with a pedestrian by causing an accident that may also lead to
      the loss of life? Who makes these decisions? The software? the
      programmers? If you were a programmer for a self-driving car, how would
      you approach such decisions? Here’s a great <url
      href="https://www.wired.com/2016/06/self-driving-cars-will-power-kill-wont-conscience/">Wired
      article</url> or <url
      href="https://www.youtube.com/watch?v=FypPSJfCRFk">BBC video</url> about
      self-driving cars and ethical problems.
    </p>

    <p>Watch the following video about the impacts of AI:</p>

    <video youtube="tJQSyzBUAew" label="video-ai" />
    <p>
      Here are some other interesting videos about the impacts of AI in
      different domains:
    </p>

    <p>
      <ul>
        <li>
          <p>
            AI in Healthcare and Radiology: <url
            href="https://www.youtube.com/watch?v=dCDuMyzWS8Q">https://www.youtube.com/watch?v=dCDuMyzWS8Q</url>
          </p>
        </li>

        <li>
          <p>
            AI in Agriculture: <url
            href="https://www.youtube.com/watch?v=DjHGG7eQevY">https://www.youtube.com/watch?v=DjHGG7eQevY</url>
          </p>
        </li>
      </ul>
    </p>
  </introduction>

  <subsection xml:id="data-privacy">
    <title>Data Privacy</title>

    <p>
      Your phone keeps a lot of information about you, including where you have
      been, what you buy, what games you play, etc. Here’s a <url
      href="https://www.youtube.com/watch?v=bqWuioPHhz0">video</url> about the
      massive amounts of data our smart phones and computers collect about us.
      If you have used your phone to give you directions to go somewhere, it
      probably tracks your location. Follow the directions in <url
      href="https://www.lifewire.com/location-history-google-maps-iphone-1683392">https://www.lifewire.com/location-history-google-maps-iphone-1683392</url>
      to see if you have location history settings on. You can also turn off
      location tracking, but it is useful when you want directions and it’s
      free. Do the benefits of apps that provide driving directions outweigh the
      lack of privacy for you? In what situations would it be beneficial or
      harmful for the app to track your location?
    </p>

    <figure align="center">
      <image source="Unit4-Data-Collections/Figures/googletimeline.png" width="100%" />
    </figure>

    <p>
      As users, we often don’t realize how much personal data we are giving
      away. If you use a computer or phone, your personal privacy is at risk. As
      computer programmers, we must be aware of the risks to data privacy when
      our code collects and stores personal data on computer systems.
      Programmers should attempt to safeguard the personal privacy of the user.
      Legally and ethically, we must ask the users for permission to access and
      store their data. And if there are data breaches where the data is stolen,
      we must inform the affected users. The laws are slowly catching up to our
      technology, and many countries and states are passing laws to protect data
      privacy.
    </p>

    <p>
      Computer use and programs have beneficial and/or harmful impacts on
      personal security. Software apps for maps and driving directions are very
      useful, but they have impacts on personal security and privacy if they
      keep track of your location. This information could be beneficial, for
      example if you are lost and need to be found, but could be harmful and
      unsafe if someone unauthorized gains access to your location.
    </p>

    <activity label="privacy">
      <statement>
        <p>
          Explore a popular app or web site and its data collecting practices.
          Explain the risks to privacy from collecting and storing personal data
          on computer systems. Discuss the ethical and legal problems that may
          arise and how programmers can try to avoid them. We encourage you to
          work on this activity in pairs or groups.
        </p>
      </statement>

      <response />
    </activity>

    <p>
      Here are some interesting video resources about data collection and data
      privacy:
    </p>

    <p>
      <ul>
        <li>
          A short <url
          href="https://www.cnbc.com/video/2018/03/23/everything-you-need-to-know-about-the-cambridge-analytica-scandal.html"
          style="text-decoration:underline">1 minute video</url> about the
          Facebook Cambridge Analytica incident and a longer <url
          href="https://www.pbs.org/wgbh/frontline/film/facebook-dilemma/#video-2"
          style="text-decoration:underline">1 hour PBS special</url> on
          Facebook.
        </li>

        <li>
          <url href="https://www.youtube.com/watch?v=gXiEBcb0Vs8" style="text-decoration:underline">What is Geo-fencing (2 mins)</url>
        </li>

        <li>
          <url href="https://www.youtube.com/watch?v=j6wwBqfSk-o" style="text-decoration:underline">The European General Data Protection Regulation (GDPR) (3 mins)</url>
        </li>
      </ul>
    </p>
  </subsection>

  <subsection xml:id="data-and-bias">
    <title>Data and Bias</title>

    <p>
      The fields of <term>AI (Artificial Intelligence)</term> and <term>Machine
      Learning (ML)</term> are rapidly growing and increasingly involve ethical
      questions about data collection, privacy, and resource use. Machine
      learning algorithms to create software like ChatGPT require massive
      amounts of data to learn from as well as massive amounts of energy use.
      But where does this data come from? Often the data is collected from the
      internet, and the internet is full of biases. For example, if you search
      for professions like “programmer”, “doctor”, “CEO” in <url
      href="https://images.google.com/">https://images.google.com/</url>, you
      will probably see mostly images of white men. This reflects a bias in our
      world that AIs may learn. An AI could then generate text or images that
      are biased against historically underrepresented groups. For example, a
      prominent tech company in 2014 started building an automated hiring tool,
      a resume filtering AI trained on their current employees resumes, and
      ended up with an AI system that was biased against women (<url
      href="https://www.aclu.org/news/womens-rights/why-amazons-automated-hiring-tool-discriminated-against">https://www.aclu.org/news/womens-rights/why-amazons-automated-hiring-tool-discriminated-against</url>).
      This is a problem because the AI is learning from biased data and then
      creating biased outcomes that could affect people’s lives.
    </p>

    <p>
      <term>Algorithmic bias</term> describes systemic and repeated errors in a
      program that create unfair outcomes for a specific group of users. Bias in
      data can lead to unfair and unethical outcomes. For instance, facial
      recognition software has been shown to have higher error rates for people
      with darker skin tones. This is because the data used to train these
      algorithms often contains fewer examples of people with darker skin tones.
      As a result, the software is less accurate for these individuals, which
      can lead to discriminatory practices.
    </p>

    <p>
      Watch the following <url
      href="https://www.youtube.com/watch?v=TWWsW1w-BVo">Gender Shades
      video</url> about gender and race bias in face recognition algorithms by
      computer scientist <url href="https://www.poetofcode.com/">Joy
      Buolamwini</url> (MIT Media Lab and Algorithmic Justice League).
    </p>

    <video youtube="TWWsW1w-BVo" label="video-gender-shades" />
    <activity label="bias">
      <statement>
        <p>
          Explain the importance of recognizing data quality and potential
          issues such as data bias when using a data set in AI/ML applications.
          (A data set or dataset is a collection or set of data.) We encourage
          you to work on this activity in pairs or groups.
        </p>
      </statement>

      <response />
    </activity>

    <p>
      Here are some other interesting videos to watch about bias in algorithms:
    </p>

    <p>
      <ul>
        <li>
          <url href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI, Ain't I a
          Woman?</url>, a poem by Joy Buolamwini
        </li>

        <li>
          Ted Talk video on <url
          href="https://www.youtube.com/watch?v=UG_X_7g63rY">Bias in Facial
          Recognition</url> by Joy Buolamwini,
        </li>

        <li>
          <url href="https://www.youtube.com/watch?v=7lpCWxlRFAw">A report on police crime prediction software and bias</url>
        </li>
      </ul>
    </p>

    <p>
      Programmers should be aware of the data set collection method and the
      potential for bias before using the data to extrapolate new information or
      drawing conclusions. Some data sets are incomplete or contain inaccurate
      data. Using such data in the development or use of a program can cause the
      program to work incorrectly or inefficiently. Or the contents of a data
      set might be related to a specific question or topic and might not be
      appropriate to give correct answers or extrapolate information for a
      different question or topic.
    </p>

    <p>
      It is important for programmers and data scientists to take steps to
      mitigate bias in data collection and use. This can include using diverse
      and representative datasets, regularly testing algorithms for bias, and
      being transparent about the limitations of the software. Here are some
      steps that can be taken to address bias in machine learning:
    </p>

    <p>
      <ul>
        <li>
          <p>Use diverse and representative data sets to train algorithms.</p>
        </li>

        <li>
          <p>Regularly test algorithms for bias and accuracy.</p>
        </li>

        <li>
          <p>
            Be transparent about the limitations and potential biases of the
            software.
          </p>
        </li>

        <li>
          <p>
            Involve diverse teams in the development and testing of algorithms.
          </p>
        </li>

        <li>
          <p>
            Implement ethical guidelines and standards for the use of AI and
            machine learning.
          </p>
        </li>
      </ul>
    </p>

    <project label="datasets">
      <statement>
        <p>
          Go to <url
          href="https://datasetsearch.research.google.com/">https://datasetsearch.research.google.com/</url>
          and search for a dataset for “face recognition” or another topic you
          are interested in. Find an appropriate (“good”) dataset and an
          inappropriate (“bad”) dataset for your topic and put links to them
          below. Explain why the datasets are appropriate or inappropriate, for
          example the inappropriate dataset might be too small or incomplete or
          biased. Explain how the choice of your dataset could affect the
          results of a program that uses the data. We encourage you to work on
          this activity in pairs or groups.
        </p>
      </statement>

      <response />
    </project>
  </subsection>

  <subsection xml:id="groupwork-impacts-of-cs">
    <title>Groupwork: Impacts of CS</title>

    <p>
      In groups, choose a software application that has social and ethical
      implications. Discuss the beneficial and harmful effects of this software
      application. Discuss the ethical problems that may arise and how
      programmers can try to avoid them. If you chose an AI application, make
      sure you narrow it to a particular domain or use. Prepare a presentation
      for your class.
    </p>

    <project label="impacts">
      <statement>
        <p>
          Describe the software application that you have chosen and discuss its
          beneficial and harmful effects.
        </p>
      </statement>

      <response />
    </project>
  </subsection>

  <subsection xml:id="summary-28">
    <title>Summary</title>

    <p>
      <ul>
        <li>
          <p>
            (AP 3.2.A.1) <term>System reliability</term> refers to the program
            being able to perform its tasks as expected under stated conditions
            without failure. Programmers should make an effort to maximize
            system reliability by testing the program with a variety of
            conditions.
          </p>
        </li>

        <li>
          <p>
            (AP 3.2.A.2) The creation of programs has impacts on society, the
            economy, and culture. These impacts can be both beneficial and
            harmful. Programs meant to fill a need or solve a problem can have
            unintended harmful effects beyond their intended use.
          </p>
        </li>

        <li>
          <p>
            (AP 3.1.A.3) Legal issues and intellectual property concerns arise
            when creating programs. Programmers often reuse code written by
            others and published as <term>open source</term> and free to use.
            Incorporation of code that is not published as open source requires
            the programmer to obtain permission and often purchase the code
            before integrating it into their program.
          </p>
        </li>
        <li>
          <p>
            (AP 4.1.A.1) When using a computer, personal privacy is at risk.
            When developing new programs, programmers should attempt to
            safeguard the personal privacy of the user.
          </p>
        </li>

        <li>
          <p>
            Computer use and the creation of programs have an impact on personal
            security and data privacy. These impacts can be beneficial and/or
            harmful.
          </p>
        </li>

        <li>
          <p>
            (AP 4.1.B.1) <term>Algorithmic bias</term> describes systemic and
            repeated errors in a program that create unfair outcomes for a
            specific group of users.
          </p>
        </li>

        <li>
          <p>
            (AP 4.1.B.2) Programmers should be aware of the data set collection
            method and the potential for bias when using this method before
            using the data to extrapolate new information or drawing
            conclusions.
          </p>
        </li>

        <li>
          <p>
            (AP 4.1.B.3) Some data sets are incomplete or contain inaccurate
            data. Using such data in the development or use of a program can
            cause the program to work incorrectly or inefficiently.
          </p>
        </li>

        <li>
          <p>
            (AP 4.1.C.1) Contents of a data set might be related to a specific
            question or topic and might not be appropriate to give correct
            answers or extrapolate information for a different question or
            topic.
          </p>
        </li>

      </ul>
    </p>
  </subsection>
</section>
